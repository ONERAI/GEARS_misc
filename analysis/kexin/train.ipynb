{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4279a2ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Printing Arguments ----\n",
      "dataset: Norman2019\n",
      "split: single_only\n",
      "seed: 1\n",
      "test_set_fraction: 0.1\n",
      "perturbation_key: condition\n",
      "species: human\n",
      "binary_pert: True\n",
      "edge_attr: True\n",
      "ctrl_remove_train: False\n",
      "edge_weights: False\n",
      "pert_feats: True\n",
      "pert_delta: False\n",
      "edge_filter: False\n",
      "network_name: string\n",
      "top_edge_percent: 10.0\n",
      "device: cuda:0\n",
      "max_epochs: 1\n",
      "lr: 0.005\n",
      "lr_decay_step_size: 3\n",
      "lr_decay_factor: 0.5\n",
      "weight_decay: 0.0005\n",
      "batch_size: 64\n",
      "print_progress_steps: 50\n",
      "node_hidden_size: 8\n",
      "node_embed_size: 1\n",
      "ae_hidden_size: 512\n",
      "gnn_num_layers: 4\n",
      "ae_num_layers: 2\n",
      "model: GNN_Disentangle_AE\n",
      "model_backend: GAT\n",
      "shared_weights: False\n",
      "pert_loss_wt: 1\n",
      "loss_type: micro\n",
      "loss_mode: l2\n",
      "focal_gamma: 2\n",
      "wandb: True\n",
      "project_name: pert_gnn_v1\n",
      "entity_name: kexinhuang\n",
      "----------------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkexinhuang\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mGAT_string_8_4_l2_Norman2019\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/kexinhuang/pert_gnn_v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/kexinhuang/pert_gnn_v1/runs/x22do22y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /dfs/user/kexinh/perturb_GNN/kexin/wandb/run-20211011_134038-x22do22y\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "Training GAT_string_8_4_l2_Norman2019\n",
      "Building cell graph... \n",
      "There are 50506 edges in the PPI.\n",
      "Creating pyg object for each cell in the data...\n",
      "Local copy of pyg dataset is detected. Loading...\n",
      "Loading splits...\n",
      "Local copy of split is detected. Loading...\n",
      "Creating dataloaders....\n",
      "Dataloaders created\n",
      "Finished data setup, in total takes 0.8058381994565328 min\n",
      "Initializing model... \n",
      "Start Training...\n",
      "Epoch 1 Step 1 Train Loss: 0.3884\n",
      "Epoch 1 Step 51 Train Loss: 0.0392\n",
      "Epoch 1 Step 101 Train Loss: 0.0423\n",
      "Epoch 1 Step 151 Train Loss: 0.0507\n",
      "Epoch 1 Step 201 Train Loss: 0.0454\n",
      "Epoch 1 Step 251 Train Loss: 0.0477\n",
      "Epoch 1 Step 301 Train Loss: 0.0402\n",
      "Epoch 1 Step 351 Train Loss: 0.0451\n",
      "Epoch 1 Step 401 Train Loss: 0.0438\n",
      "Epoch 1 Step 451 Train Loss: 0.0366\n",
      "Epoch 1 Step 501 Train Loss: 0.0468\n",
      "Epoch 1 Step 551 Train Loss: 0.0437\n",
      "Epoch 1 Step 601 Train Loss: 0.0375\n",
      "Epoch 1 Step 651 Train Loss: 0.0427\n",
      "Epoch 1: Train: 0.0043, R2 0.9708 Validation: 0.0044. R2 0.9703 Loss: 0.0453\n",
      "DE_Train: 0.2855, R2 0.5529 DE_Validation: 0.2756. R2 0.6805 \n",
      "Start testing....\n",
      "Final best performing model: Test_DE: 0.2077, R2 0.3332 \n",
      "Saving model....\n",
      "Done!\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 44962\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: /dfs/user/kexinh/perturb_GNN/kexin/wandb/run-20211011_134038-x22do22y/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: /dfs/user/kexinh/perturb_GNN/kexin/wandb/run-20211011_134038-x22do22y/logs/debug-internal.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Test_DE_MSE 0.20767\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Test_R2 0.33322\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_de_mse 0.28553\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_de_r2 0.55286\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_mse 0.00434\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_r2 0.97082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   training_loss 0.03998\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_de_mse 0.27558\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_de_r2 0.68051\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_mse 0.00442\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_r2 0.97027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     Test_DE_MSE ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         Test_R2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    train_de_mse ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     train_de_r2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       train_mse ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        train_r2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   training_loss █▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▂▁▂▂▂▂▂▁▁▂▂▂▂▂▁▂▂\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      val_de_mse ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       val_de_r2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         val_mse ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          val_r2 ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mGAT_string_8_4_l2_Norman2019\u001b[0m: \u001b[34mhttps://wandb.ai/kexinhuang/pert_gnn_v1/runs/x22do22y\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset Norman2019 \\\n",
    "                 --split single_only \\\n",
    "                 --seed 1 \\\n",
    "                 --test_set_fraction 0.1 \\\n",
    "                 --network_name string \\\n",
    "                 --top_edge_percent 10 \\\n",
    "                 --max_epochs 1 \\\n",
    "                 --batch_size 64 \\\n",
    "                 --lr 5e-3 \\\n",
    "                 --lr_decay_step_size 3 \\\n",
    "                 --lr_decay_factor 0.5 \\\n",
    "                 --weight_decay 5e-4 \\\n",
    "                 --model GNN_Disentangle_AE \\\n",
    "                 --model_backend GAT \\\n",
    "                 --node_hidden_size 8 \\\n",
    "                 --gnn_num_layers 4 \\\n",
    "                 --ae_hidden_size 512 \\\n",
    "                 --ae_num_layers 2\\\n",
    "                 --loss_mode l2 \\\n",
    "                 --focal_gamma 2 \\\n",
    "                 --print_progress_steps 50 \\\n",
    "                 --device cuda:0 \\\n",
    "                 --wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b32b172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
